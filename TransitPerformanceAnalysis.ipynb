{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d5ea6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b50e0853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 1: Load and Explore Data\n",
    "\n",
    "def load_json_data(filepath):\n",
    "    \"\"\"\n",
    "    Load JSON data from file\n",
    "    \"\"\"\n",
    "    with open(filepath, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def explore_data(data):\n",
    "    \"\"\"\n",
    "    Perform initial data exploration\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"DATA EXPLORATION\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Number of records in dataset: {len(data)}\")\n",
    "    \n",
    "    # Extract shipment records\n",
    "    shipment_records = [detail for item in data for detail in item.get('trackDetails', [])]\n",
    "    print(f\"Total shipments to analyze: {len(shipment_records)}\")\n",
    "    \n",
    "    if shipment_records:\n",
    "        print(\"\\nSample shipment keys:\")\n",
    "        print(list(shipment_records[0].keys())[:10])\n",
    "    \n",
    "    return shipment_records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "642f7582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 2: Flatten and Extract Transit Data\n",
    "\n",
    "def safe_get(dictionary, *keys, default=None):\n",
    "    \"\"\"\n",
    "    Safely navigate nested dictionary structure\n",
    "    \"\"\"\n",
    "    result = dictionary\n",
    "    for key in keys:\n",
    "        if isinstance(result, dict):\n",
    "            result = result.get(key, default)\n",
    "        else:\n",
    "            return default\n",
    "    return result if result is not None else default\n",
    "\n",
    "def parse_timestamp(ts_value):\n",
    "    \"\"\"\n",
    "    Parse timestamp from various formats (MongoDB $numberLong or ISO string)\n",
    "    Returns datetime object or None\n",
    "    \"\"\"\n",
    "    if ts_value is None:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Handle MongoDB $numberLong format\n",
    "        if isinstance(ts_value, dict) and '$numberLong' in ts_value:\n",
    "            timestamp_ms = int(ts_value['$numberLong'])\n",
    "            return datetime.fromtimestamp(timestamp_ms / 1000.0)\n",
    "        \n",
    "        # Handle ISO string format\n",
    "        elif isinstance(ts_value, str):\n",
    "            # Try multiple datetime formats\n",
    "            for fmt in ['%Y-%m-%dT%H:%M:%S%z', '%Y-%m-%dT%H:%M:%S', '%Y-%m-%d']:\n",
    "                try:\n",
    "                    return datetime.strptime(ts_value.split('.')[0].replace('+05:30', ''), \n",
    "                                           fmt.replace('%z', ''))\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        # Handle direct integer timestamp\n",
    "        elif isinstance(ts_value, (int, float)):\n",
    "            return datetime.fromtimestamp(ts_value / 1000.0)\n",
    "    \n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "    return None\n",
    "\n",
    "def extract_shipment_data(shipment):\n",
    "    \"\"\"\n",
    "    Extract and flatten all shipment information\n",
    "    \"\"\"\n",
    "    # Basic shipment identifiers\n",
    "    tracking_number = safe_get(shipment, 'trackingNumber', default='')\n",
    "    service_type = safe_get(shipment, 'service', 'type', default='')\n",
    "    service_description = safe_get(shipment, 'service', 'description', default='')\n",
    "    carrier_code = safe_get(shipment, 'carrierCode', default='')\n",
    "    \n",
    "    # Weight and package information\n",
    "    package_weight_value = safe_get(shipment, 'packageWeight', 'value', default=0)\n",
    "    package_weight_units = safe_get(shipment, 'packageWeight', 'units', default='KG')\n",
    "    packaging_type = safe_get(shipment, 'packaging', 'type', default='')\n",
    "    \n",
    "    # Convert weight to KG if needed\n",
    "    if package_weight_units == 'LB':\n",
    "        package_weight_kg = package_weight_value * 0.453592\n",
    "    else:\n",
    "        package_weight_kg = package_weight_value\n",
    "    \n",
    "    # Origin information\n",
    "    origin_city = safe_get(shipment, 'shipperAddress', 'city', default='')\n",
    "    origin_state = safe_get(shipment, 'shipperAddress', 'stateOrProvinceCode', default='')\n",
    "    origin_pincode = safe_get(shipment, 'shipperAddress', 'postalCode', default='')\n",
    "    \n",
    "    # Destination information\n",
    "    destination_city = safe_get(shipment, 'destinationAddress', 'city', default='')\n",
    "    destination_state = safe_get(shipment, 'destinationAddress', 'stateOrProvinceCode', default='')\n",
    "    destination_pincode = safe_get(shipment, 'destinationAddress', 'postalCode', default='')\n",
    "    \n",
    "    # Delivery characteristics\n",
    "    delivery_location_type = safe_get(shipment, 'deliveryLocationType', default='')\n",
    "    \n",
    "    # Extract events\n",
    "    events = safe_get(shipment, 'events', default=[])\n",
    "    \n",
    "    return {\n",
    "        'tracking_number': tracking_number,\n",
    "        'service_type': service_type,\n",
    "        'service_description': service_description,\n",
    "        'carrier_code': carrier_code,\n",
    "        'package_weight_kg': package_weight_kg,\n",
    "        'packaging_type': packaging_type,\n",
    "        'origin_city': origin_city,\n",
    "        'origin_state': origin_state,\n",
    "        'origin_pincode': origin_pincode,\n",
    "        'destination_city': destination_city,\n",
    "        'destination_state': destination_state,\n",
    "        'destination_pincode': destination_pincode,\n",
    "        'delivery_location_type': delivery_location_type,\n",
    "        'events': events\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab24ce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 3: Compute Transit Performance Metrics\n",
    "def compute_transit_metrics(shipment_data):\n",
    "    \"\"\"\n",
    "    Calculate all transit performance metrics for a shipment\n",
    "    \"\"\"\n",
    "    events = shipment_data['events']\n",
    "    \n",
    "    # Initialize metrics\n",
    "    metrics = {\n",
    "        'num_facilities_visited': 0,\n",
    "        'facility_list': [],\n",
    "        'event_type_counts': {},\n",
    "        'unique_event_types': set(),\n",
    "        'total_transit_hours': 0,\n",
    "        'pickup_datetime_ist': None,\n",
    "        'delivery_datetime_ist': None,\n",
    "        'time_in_inter_facility_transit_hours': 0,\n",
    "        'avg_hours_per_facility': 0,\n",
    "        'is_express_service': False,\n",
    "        'num_out_for_delivery_attempts': 0,\n",
    "        'first_attempt_delivery': False,\n",
    "        'total_events_count': len(events),\n",
    "        'num_in_transit_events': 0\n",
    "    }\n",
    "    \n",
    "    if not events:\n",
    "        return metrics\n",
    "    \n",
    "    # Parse all event timestamps and types\n",
    "    parsed_events = []\n",
    "    for event in events:\n",
    "        event_type = safe_get(event, 'eventType', default='')\n",
    "        event_desc = safe_get(event, 'eventDescription', default='')\n",
    "        timestamp = parse_timestamp(safe_get(event, 'timestamp'))\n",
    "        arrival_location = safe_get(event, 'arrivalLocation', default='')\n",
    "        city = safe_get(event, 'address', 'city', default='')\n",
    "        \n",
    "        if timestamp:\n",
    "            parsed_events.append({\n",
    "                'timestamp': timestamp,\n",
    "                'event_type': event_type,\n",
    "                'event_desc': event_desc,\n",
    "                'arrival_location': arrival_location,\n",
    "                'city': city\n",
    "            })\n",
    "        \n",
    "        # Track unique event types\n",
    "        if event_type:\n",
    "            metrics['unique_event_types'].add(event_type)\n",
    "            metrics['event_type_counts'][event_type] = metrics['event_type_counts'].get(event_type, 0) + 1\n",
    "        \n",
    "        # Count facilities visited\n",
    "        if arrival_location and 'FACILITY' in arrival_location.upper():\n",
    "            if arrival_location not in metrics['facility_list']:\n",
    "                metrics['facility_list'].append(arrival_location)\n",
    "        \n",
    "        # Count out-for-delivery attempts\n",
    "        if event_type in ['OD', 'OFD'] or 'OUT FOR DELIVERY' in event_desc.upper():\n",
    "            metrics['num_out_for_delivery_attempts'] += 1\n",
    "        \n",
    "        # Count in-transit events\n",
    "        if event_type in ['IT', 'DP', 'AR']:\n",
    "            metrics['num_in_transit_events'] += 1\n",
    "    \n",
    "    # Sort events by timestamp\n",
    "    parsed_events.sort(key=lambda x: x['timestamp'])\n",
    "    \n",
    "    # Calculate transit time\n",
    "    if parsed_events:\n",
    "        # Find pickup event (PU, PL, OC)\n",
    "        pickup_events = [e for e in parsed_events if e['event_type'] in ['PU', 'PL', 'OC', 'PK']]\n",
    "        if pickup_events:\n",
    "            metrics['pickup_datetime_ist'] = pickup_events[0]['timestamp']\n",
    "        else:\n",
    "            # Use first event if no pickup found\n",
    "            metrics['pickup_datetime_ist'] = parsed_events[0]['timestamp']\n",
    "        \n",
    "        # Find delivery event (DL, DD, DEL)\n",
    "        delivery_events = [e for e in parsed_events if e['event_type'] in ['DL', 'DD', 'DEL']]\n",
    "        if delivery_events:\n",
    "            metrics['delivery_datetime_ist'] = delivery_events[-1]['timestamp']\n",
    "        else:\n",
    "            # Use last event if no delivery found\n",
    "            metrics['delivery_datetime_ist'] = parsed_events[-1]['timestamp']\n",
    "        \n",
    "        # Calculate total transit hours\n",
    "        if metrics['pickup_datetime_ist'] and metrics['delivery_datetime_ist']:\n",
    "            time_diff = metrics['delivery_datetime_ist'] - metrics['pickup_datetime_ist']\n",
    "            metrics['total_transit_hours'] = time_diff.total_seconds() / 3600.0\n",
    "    \n",
    "    # Calculate facility metrics\n",
    "    metrics['num_facilities_visited'] = len(metrics['facility_list'])\n",
    "    \n",
    "    if metrics['num_facilities_visited'] > 0 and metrics['total_transit_hours'] > 0:\n",
    "        metrics['avg_hours_per_facility'] = metrics['total_transit_hours'] / metrics['num_facilities_visited']\n",
    "    \n",
    "    # Calculate inter-facility transit time (approximate)\n",
    "    # Time between facility arrivals\n",
    "    facility_events = [e for e in parsed_events if 'FACILITY' in e['arrival_location'].upper()]\n",
    "    if len(facility_events) > 1:\n",
    "        inter_facility_time = 0\n",
    "        for i in range(1, len(facility_events)):\n",
    "            time_diff = facility_events[i]['timestamp'] - facility_events[i-1]['timestamp']\n",
    "            inter_facility_time += time_diff.total_seconds() / 3600.0\n",
    "        metrics['time_in_inter_facility_transit_hours'] = inter_facility_time\n",
    "    \n",
    "    # Classify service type\n",
    "    service_type = shipment_data['service_type'].upper()\n",
    "    express_keywords = ['EXPRESS', 'PRIORITY', 'OVERNIGHT', 'NEXT_DAY', 'FIRST', 'SAVER']\n",
    "    metrics['is_express_service'] = any(keyword in service_type for keyword in express_keywords)\n",
    "    \n",
    "    # Check first attempt delivery\n",
    "    metrics['first_attempt_delivery'] = metrics['num_out_for_delivery_attempts'] <= 1\n",
    "    \n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8b2f3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 4 & 5: Process All Shipments and Create Detailed CSV\n",
    "\n",
    "def process_all_shipments(shipment_records):\n",
    "    \"\"\"\n",
    "    Process all shipments and create detailed records\n",
    "    \"\"\"\n",
    "    detailed_records = []\n",
    "    \n",
    "    for shipment in shipment_records:\n",
    "        try:\n",
    "            # Extract basic data\n",
    "            shipment_data = extract_shipment_data(shipment)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            metrics = compute_transit_metrics(shipment_data)\n",
    "            \n",
    "            # Combine into final record\n",
    "            record = {\n",
    "                'tracking_number': shipment_data['tracking_number'],\n",
    "                'service_type': shipment_data['service_type'],\n",
    "                'carrier_code': shipment_data['carrier_code'],\n",
    "                'package_weight_kg': round(shipment_data['package_weight_kg'], 2),\n",
    "                'packaging_type': shipment_data['packaging_type'],\n",
    "                'origin_city': shipment_data['origin_city'],\n",
    "                'origin_state': shipment_data['origin_state'],\n",
    "                'origin_pincode': shipment_data['origin_pincode'],\n",
    "                'destination_city': shipment_data['destination_city'],\n",
    "                'destination_state': shipment_data['destination_state'],\n",
    "                'destination_pincode': shipment_data['destination_pincode'],\n",
    "                'pickup_datetime_ist': metrics['pickup_datetime_ist'],\n",
    "                'delivery_datetime_ist': metrics['delivery_datetime_ist'],\n",
    "                'total_transit_hours': round(metrics['total_transit_hours'], 2),\n",
    "                'num_facilities_visited': metrics['num_facilities_visited'],\n",
    "                'num_in_transit_events': metrics['num_in_transit_events'],\n",
    "                'time_in_inter_facility_transit_hours': round(metrics['time_in_inter_facility_transit_hours'], 2),\n",
    "                'avg_hours_per_facility': round(metrics['avg_hours_per_facility'], 2),\n",
    "                'is_express_service': metrics['is_express_service'],\n",
    "                'delivery_location_type': shipment_data['delivery_location_type'],\n",
    "                'num_out_for_delivery_attempts': metrics['num_out_for_delivery_attempts'],\n",
    "                'first_attempt_delivery': metrics['first_attempt_delivery'],\n",
    "                'total_events_count': metrics['total_events_count']\n",
    "            }\n",
    "            \n",
    "            detailed_records.append(record)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing shipment: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(detailed_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8598bbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 6: Generate Network Performance Summary\n",
    "\n",
    "def generate_summary(df):\n",
    "    \"\"\"\n",
    "    Generate network performance summary statistics\n",
    "    \"\"\"\n",
    "    summary = {}\n",
    "    \n",
    "    # Overall Metrics\n",
    "    summary['total_shipments_analyzed'] = len(df)\n",
    "    summary['avg_transit_hours'] = round(df['total_transit_hours'].mean(), 2)\n",
    "    summary['median_transit_hours'] = round(df['total_transit_hours'].median(), 2)\n",
    "    summary['std_dev_transit_hours'] = round(df['total_transit_hours'].std(), 2)\n",
    "    summary['min_transit_hours'] = round(df['total_transit_hours'].min(), 2)\n",
    "    summary['max_transit_hours'] = round(df['total_transit_hours'].max(), 2)\n",
    "    \n",
    "    # Facility Metrics\n",
    "    summary['avg_facilities_per_shipment'] = round(df['num_facilities_visited'].mean(), 2)\n",
    "    summary['median_facilities_per_shipment'] = round(df['num_facilities_visited'].median(), 2)\n",
    "    \n",
    "    # Mode calculation\n",
    "    mode_result = df['num_facilities_visited'].mode()\n",
    "    summary['mode_facilities_per_shipment'] = int(mode_result.iloc[0]) if len(mode_result) > 0 else 0\n",
    "    \n",
    "    summary['avg_hours_per_facility'] = round(df['avg_hours_per_facility'].mean(), 2)\n",
    "    summary['median_hours_per_facility'] = round(df['avg_hours_per_facility'].median(), 2)\n",
    "    \n",
    "    # Service Type Comparison\n",
    "    service_groups = df.groupby('service_type').agg({\n",
    "        'total_transit_hours': 'mean',\n",
    "        'num_facilities_visited': 'mean',\n",
    "        'tracking_number': 'count'\n",
    "    }).round(2)\n",
    "    \n",
    "    for service_type, row in service_groups.iterrows():\n",
    "        summary[f'avg_transit_hours_{service_type}'] = row['total_transit_hours']\n",
    "        summary[f'avg_facilities_{service_type}'] = row['num_facilities_visited']\n",
    "        summary[f'count_shipments_{service_type}'] = int(row['tracking_number'])\n",
    "    \n",
    "    # Delivery Performance\n",
    "    summary['pct_first_attempt_delivery'] = round(\n",
    "        (df['first_attempt_delivery'].sum() / len(df)) * 100, 2\n",
    "    )\n",
    "    summary['avg_out_for_delivery_attempts'] = round(\n",
    "        df['num_out_for_delivery_attempts'].mean(), 2\n",
    "    )\n",
    "    \n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "843a2332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Transit Performance Analysis...\n",
      "\n",
      "================================================================================\n",
      "DATA EXPLORATION\n",
      "================================================================================\n",
      "Number of records in dataset: 99\n",
      "Total shipments to analyze: 99\n",
      "\n",
      "Sample shipment keys:\n",
      "['notification', 'trackingNumber', 'trackingNumberUniqueIdentifier', 'statusDetail', 'informationNotes', 'customerExceptionRequests', 'carrierCode', 'operatingCompanyOrCarrierDescription', 'otherIdentifiers', 'service']\n",
      "\n",
      "Processing shipments and calculating metrics...\n",
      "Successfully processed 99 shipments\n",
      "\n",
      "✓ Saved detailed results to: transit_performance_detailed.csv\n",
      "✓ Saved summary results to: transit_performance_summary.csv\n",
      "\n",
      "================================================================================\n",
      "PREVIEW OF RESULTS\n",
      "================================================================================\n",
      "\n",
      "Detailed Data (first 5 rows):\n",
      "  tracking_number         service_type carrier_code  package_weight_kg  \\\n",
      "0    391128701026  FEDEX_EXPRESS_SAVER         FDXE               14.0   \n",
      "1    390901883808  FEDEX_EXPRESS_SAVER         FDXE               14.0   \n",
      "2    391128749178  FEDEX_EXPRESS_SAVER         FDXE               14.0   \n",
      "3    390807986805  FEDEX_EXPRESS_SAVER         FDXE               14.0   \n",
      "4    390948921190  FEDEX_EXPRESS_SAVER         FDXE               14.0   \n",
      "\n",
      "   packaging_type origin_city origin_state origin_pincode destination_city  \\\n",
      "0  YOUR_PACKAGING   Bangalore           KA                         Gurgaon   \n",
      "1  YOUR_PACKAGING   Bangalore           KA                       Bangalore   \n",
      "2  YOUR_PACKAGING   Bangalore           KA                       Ahmedabad   \n",
      "3  YOUR_PACKAGING   Bangalore           KA                       New Delhi   \n",
      "4  YOUR_PACKAGING   Bangalore           KA                           Delhi   \n",
      "\n",
      "  destination_state  ... total_transit_hours num_facilities_visited  \\\n",
      "0                HR  ...               95.38                      3   \n",
      "1                KA  ...               79.87                      3   \n",
      "2                GJ  ...               73.17                      3   \n",
      "3                DL  ...               97.82                      2   \n",
      "4                DL  ...               99.08                      3   \n",
      "\n",
      "  num_in_transit_events  time_in_inter_facility_transit_hours  \\\n",
      "0                     7                                 82.40   \n",
      "1                     7                                 60.13   \n",
      "2                     8                                 56.43   \n",
      "3                     6                                 81.62   \n",
      "4                     7                                 83.00   \n",
      "\n",
      "   avg_hours_per_facility  is_express_service      delivery_location_type  \\\n",
      "0                   31.79                True                   RESIDENCE   \n",
      "1                   26.62                True  RECEPTIONIST_OR_FRONT_DESK   \n",
      "2                   24.39                True                   RESIDENCE   \n",
      "3                   48.91                True                   RESIDENCE   \n",
      "4                   33.03                True                   RESIDENCE   \n",
      "\n",
      "   num_out_for_delivery_attempts  first_attempt_delivery total_events_count  \n",
      "0                              1                    True                 11  \n",
      "1                              2                   False                 12  \n",
      "2                              1                    True                 12  \n",
      "3                              1                    True                 10  \n",
      "4                              1                    True                 11  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "Summary Statistics:\n",
      "                                            0\n",
      "total_shipments_analyzed                99.00\n",
      "avg_transit_hours                      100.86\n",
      "median_transit_hours                    97.24\n",
      "std_dev_transit_hours                   66.09\n",
      "min_transit_hours                       20.60\n",
      "max_transit_hours                      545.53\n",
      "avg_facilities_per_shipment              2.83\n",
      "median_facilities_per_shipment           3.00\n",
      "mode_facilities_per_shipment             3.00\n",
      "avg_hours_per_facility                  36.51\n",
      "median_hours_per_facility               32.80\n",
      "avg_transit_hours_FEDEX_EXPRESS_SAVER  100.86\n",
      "avg_facilities_FEDEX_EXPRESS_SAVER       2.83\n",
      "count_shipments_FEDEX_EXPRESS_SAVER     99.00\n",
      "pct_first_attempt_delivery              84.85\n",
      "avg_out_for_delivery_attempts            0.97\n",
      "\n",
      "Analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# MAIN EXECUTION\n",
    "\n",
    "def main(json_filepath):\n",
    "    \"\"\"\n",
    "    Main execution function\n",
    "    \"\"\"\n",
    "    print(\"Starting Transit Performance Analysis...\")\n",
    "    print()\n",
    "    \n",
    "    # Load data\n",
    "    data = load_json_data(json_filepath)\n",
    "    shipment_records = explore_data(data)\n",
    "    print()\n",
    "    \n",
    "    # Process all shipments\n",
    "    print(\"Processing shipments and calculating metrics...\")\n",
    "    detailed_df = process_all_shipments(shipment_records)\n",
    "    print(f\"Successfully processed {len(detailed_df)} shipments\")\n",
    "    print()\n",
    "    \n",
    "    # Save detailed CSV\n",
    "    output_detailed = 'transit_performance_detailed.csv'\n",
    "    detailed_df.to_csv(output_detailed, index=False)\n",
    "    print(f\"✓ Saved detailed results to: {output_detailed}\")\n",
    "    \n",
    "    # Generate and save summary\n",
    "    summary = generate_summary(detailed_df)\n",
    "    summary_df = pd.DataFrame([summary])\n",
    "    output_summary = 'transit_performance_summary.csv'\n",
    "    summary_df.to_csv(output_summary, index=False)\n",
    "    print(f\"✓ Saved summary results to: {output_summary}\")\n",
    "    print()\n",
    "    \n",
    "    # Display preview\n",
    "    print(\"=\" * 80)\n",
    "    print(\"PREVIEW OF RESULTS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nDetailed Data (first 5 rows):\")\n",
    "    print(detailed_df.head())\n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    print(summary_df.transpose())\n",
    "    print()\n",
    "    \n",
    "    print(\"Analysis complete!\")\n",
    "    return detailed_df, summary_df\n",
    "\n",
    "# ============================================================================\n",
    "# RUN THE ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your actual JSON file path\n",
    "    json_file = 'Swift Assignment 4 - Dataset (1).json'\n",
    "    \n",
    "    try:\n",
    "        detailed_df, summary_df = main(json_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find file '{json_file}'\")\n",
    "        print(\"Please update the 'json_file' variable with the correct path to your JSON file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bd868ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Load the detailed performance data generated in the previous step\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the detailed performance data generated in the previous step\n",
    "detailed_df = pd.read_csv('transit_performance_detailed.csv')\n",
    "\n",
    "# --- 1. Data Cleaning for Visualization ---\n",
    "# Drop rows where total_transit_hours is NaN (e.g., incomplete events) to clean the analysis scope\n",
    "df_clean = detailed_df.dropna(subset=['total_transit_hours']).copy()\n",
    "\n",
    "# --- 2. Create Visualizations (Graphs) ---\n",
    "\n",
    "# Set a consistent style for better presentation\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# 2.1. Histogram of Total Transit Hours (Distribution Analysis)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_clean['total_transit_hours'], bins=20, kde=True, color='skyblue')\n",
    "plt.title('Distribution of Total Transit Time (Hours)')\n",
    "plt.xlabel('Total Transit Hours')\n",
    "plt.ylabel('Number of Shipments')\n",
    "plt.tight_layout()\n",
    "plt.savefig('transit_time_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# 2.2. Comparative Bar Chart: Average Transit Hours by Origin State (Performance Comparison)\n",
    "# Group by origin state and calculate mean transit time\n",
    "state_performance = df_clean.groupby('origin_state')['total_transit_hours'].mean().reset_index()\n",
    "state_performance = state_performance.sort_values(by='total_transit_hours', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='origin_state', y='total_transit_hours', data=state_performance, palette='viridis')\n",
    "plt.title('Average Transit Hours by Origin State')\n",
    "plt.xlabel('Origin State')\n",
    "plt.ylabel('Average Transit Hours')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('avg_transit_time_by_state.png')\n",
    "plt.close()\n",
    "\n",
    "# 2.3. Bar Chart of Facility Touchpoints Distribution\n",
    "facility_dist = df_clean['num_facilities_visited'].value_counts().sort_index().reset_index()\n",
    "facility_dist.columns = ['num_facilities_visited', 'count']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='num_facilities_visited', y='count', data=facility_dist, palette='magma')\n",
    "plt.title('Distribution of Facility Touchpoints per Shipment')\n",
    "plt.xlabel('Number of Unique Facilities Visited')\n",
    "plt.ylabel('Number of Shipments')\n",
    "plt.tight_layout()\n",
    "plt.savefig('facility_touchpoints_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# --- 3. Advanced Analysis: Outlier Detection (Finding the \"Worst Performers\") ---\n",
    "\n",
    "# Identify the top 5 shipments with the longest transit time\n",
    "worst_performers = df_clean.sort_values(by='total_transit_hours', ascending=False).head(5)\n",
    "\n",
    "# Select relevant columns for display\n",
    "worst_performers_summary = worst_performers[[\n",
    "    'tracking_number', \n",
    "    'origin_city', \n",
    "    'destination_city', \n",
    "    'total_transit_hours', \n",
    "    'num_facilities_visited',\n",
    "    'first_attempt_delivery'\n",
    "]]\n",
    "\n",
    "# The summary table printed above is the output of this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0525ce6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
